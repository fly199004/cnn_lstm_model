{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN-LSTM模型的运行情况 \n",
    "没有调整参数前的状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# 定义批次大小和统一的向量维度\n",
    "BATCH_SIZE = 8\n",
    "UNIFORM_LENGTH = 512  # 假设所有词向量都填充或截断到这个长度\n",
    "FEATURE_DIM = 768     # BERT基本模型的特征维度\n",
    "batch_size = 8  \n",
    "\n",
    "\n",
    "# 2. 修改数据加载器以同时读取特征和标签\n",
    "def data_generator(file_paths, batch_size):    \n",
    "    for file_path in file_paths:\n",
    "        print(\"Loading file:\", file_path)  # 调试输出\n",
    "        batch_data = np.load(file_path, allow_pickle=True).item()\n",
    "        features = batch_data['features']\n",
    "        labels = batch_data['labels']\n",
    "        # 根据批次大小将数据分块\n",
    "        for i in range(0, len(features), batch_size):\n",
    "            print(\"Loaded data shape:\", features.shape, labels.shape)  # 调试输出\n",
    "            yield features[i:i+batch_size], labels[i:i+batch_size]\n",
    "\n",
    "\n",
    "def load_dataset(file_paths, batch_size):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: data_generator(file_paths, batch_size),\n",
    "        output_types=(tf.float32, tf.int32),\n",
    "        output_shapes=((batch_size, UNIFORM_LENGTH, FEATURE_DIM), (batch_size,))\n",
    "    )\n",
    "    return dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 695\n",
      "Validation files: 150\n",
      "Test files: 150\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17740\\1494565880.py:29: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17740\\1494565880.py:29: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "训练集为： <_PrefetchDataset element_spec=(TensorSpec(shape=(8, 512, 768), dtype=tf.float32, name=None), TensorSpec(shape=(8,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集\n",
    "vector_dir = 'bert_vectors'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "files = [os.path.join(vector_dir, file) for file in sorted(os.listdir(vector_dir)) if file.endswith('.npy')]\n",
    "# 确保去除数据量不足的最后一个文件\n",
    "sample_data = np.load(files[-1], allow_pickle=True).item()\n",
    "if sample_data['features'].shape[0] < BATCH_SIZE:\n",
    "    files = files[:-1]\n",
    "\n",
    "# 指定训练集、验证集和测试集的比例\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15  # Note: train_size + val_size + test_size should be 1\n",
    "\n",
    "# 计算划分的索引\n",
    "# 划分训练集、验证集、测试集文件列表\n",
    "train_files, test_files = train_test_split(files, test_size=test_size, random_state=42)\n",
    "train_files, val_files = train_test_split(train_files, test_size=val_size / (train_size + val_size), random_state=42)\n",
    "\n",
    "# 现在你有了训练集(train_files)、验证集(val_files)和测试集(test_files)的文件列表\n",
    "print(f\"Train files: {len(train_files)}\")\n",
    "print(f\"Validation files: {len(val_files)}\")\n",
    "print(f\"Test files: {len(test_files)}\")\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = load_dataset(train_files, batch_size)\n",
    "val_dataset = load_dataset(val_files, batch_size)\n",
    "test_dataset = load_dataset(test_files, batch_size)\n",
    "\n",
    "print(\"训练集为：\",train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: bert_vectors\\batch_0640.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0479.npy\n",
      "Features shape: (8, 512, 768)\n",
      "Labels shape: (8,)\n",
      "Loaded data shape: (8, 512, 768) (8,)\n"
     ]
    }
   ],
   "source": [
    "for features, labels in train_dataset.take(1):\n",
    "    print(\"Features shape:\", features.shape)\n",
    "    print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_3x1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ maxpool_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_4x1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ maxpool_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_5x1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ maxpool_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_3x1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m147,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ maxpool_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_4x1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ maxpool_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_5x1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m164,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ maxpool_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm (\u001b[38;5;33mBatchNormalization\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">772,930</span> (2.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m772,930\u001b[0m (2.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">772,418</span> (2.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m772,418\u001b[0m (2.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "\n",
    "def create_cnn_lstm_model(sequence_length, vector_dimension, num_classes):\n",
    "    # 输入层\n",
    "    input_layer = Input(shape=(sequence_length, vector_dimension), name=\"input\")\n",
    "    \n",
    "    # 卷积和池化层\n",
    "    conv_3 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', name=\"conv_3x1\")(input_layer)\n",
    "    pool_3 = MaxPooling1D(pool_size=2, name=\"maxpool_3\")(conv_3)\n",
    "    conv_4 = Conv1D(filters=128, kernel_size=4, activation='relu', padding='same', name=\"conv_4x1\")(pool_3)\n",
    "    pool_4 = MaxPooling1D(pool_size=2, name=\"maxpool_4\")(conv_4)\n",
    "    conv_5 = Conv1D(filters=256, kernel_size=5, activation='relu', padding='same', name=\"conv_5x1\")(pool_4)\n",
    "    pool_5 = MaxPooling1D(pool_size=2, name=\"maxpool_5\")(conv_5)\n",
    "    \n",
    "    # Batch Normalization\n",
    "    batch_norm = BatchNormalization(name=\"batch_norm\")(pool_5)\n",
    "    \n",
    "    # 双向LSTM层\n",
    "    lstm_layer = Bidirectional(LSTM(128, return_sequences=False, name=\"lstm_layer\"))(batch_norm)\n",
    "    \n",
    "    # 全连接层和Dropout\n",
    "    dense_layer = Dense(128, activation='relu', name=\"dense_layer\")(lstm_layer)\n",
    "    dropout_layer = Dropout(0.5, name=\"dropout_layer\")(dense_layer)\n",
    "    \n",
    "    # 输出层\n",
    "    output_layer = Dense(num_classes, activation='softmax', name=\"output_layer\")(dropout_layer)\n",
    "    \n",
    "    # 构建模型\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# 模型参数\n",
    "sequence_length = 512  # 序列长度\n",
    "vector_dimension = 768  # 特征维度，如BERT词向量维度\n",
    "num_classes = 2  # 类别数，如正面、负面\n",
    "\n",
    "# 创建并编译模型\n",
    "model = create_cnn_lstm_model(sequence_length, vector_dimension, num_classes)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy', 'precision', 'recall', 'AUC'])\n",
    "\n",
    "# 打印模型概览\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 8 and 16 for '{{node LogicalAnd}} = LogicalAnd[](Tile_2, Greater)' with input shapes: [1,8], [1,16].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 现在使用创建的模型进行训练\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py:1267\u001b[0m, in \u001b[0;36mlogical_and\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m   1265\u001b[0m x1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(x1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1266\u001b[0m x2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(x2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_and\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 8 and 16 for '{{node LogicalAnd}} = LogicalAnd[](Tile_2, Greater)' with input shapes: [1,8], [1,16]."
     ]
    }
   ],
   "source": [
    "# 现在使用创建的模型进行训练\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: bert_vectors\\batch_0962.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0173.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      1/Unknown \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0029Loading file: bert_vectors\\batch_0709.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0295.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      3/Unknown \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0086Loading file: bert_vectors\\batch_0899.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0921.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      5/Unknown \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0133Loading file: bert_vectors\\batch_0189.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0989.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      7/Unknown \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0156Loading file: bert_vectors\\batch_0480.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0593.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      9/Unknown \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9904 - loss: 0.0344Loading file: bert_vectors\\batch_0879.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0942.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     11/Unknown \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9834 - loss: 0.0478Loading file: bert_vectors\\batch_0458.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0356.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     13/Unknown \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9798 - loss: 0.0547Loading file: bert_vectors\\batch_0297.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0984.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     15/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9768 - loss: 0.0605Loading file: bert_vectors\\batch_0504.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0836.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     17/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9746 - loss: 0.0644Loading file: bert_vectors\\batch_0964.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0147.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     19/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9730 - loss: 0.0668Loading file: bert_vectors\\batch_0416.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0863.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     21/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9718 - loss: 0.0690Loading file: bert_vectors\\batch_0587.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0126.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     23/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9706 - loss: 0.0709Loading file: bert_vectors\\batch_0169.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0876.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     25/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9685 - loss: 0.0751Loading file: bert_vectors\\batch_0358.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0912.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     27/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9668 - loss: 0.0792Loading file: bert_vectors\\batch_0046.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0163.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     29/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9653 - loss: 0.0839Loading file: bert_vectors\\batch_0641.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0089.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     31/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9641 - loss: 0.0878Loading file: bert_vectors\\batch_0770.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0366.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     33/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9628 - loss: 0.0912Loading file: bert_vectors\\batch_0476.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0196.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     35/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9611 - loss: 0.0960Loading file: bert_vectors\\batch_0311.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0247.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     37/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9592 - loss: 0.1012Loading file: bert_vectors\\batch_0769.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0885.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     39/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9576 - loss: 0.1057Loading file: bert_vectors\\batch_0382.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0495.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     41/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9560 - loss: 0.1099Loading file: bert_vectors\\batch_0950.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0965.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     43/Unknown \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9546 - loss: 0.1138Loading file: bert_vectors\\batch_0252.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0424.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     45/Unknown \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9535 - loss: 0.1171Loading file: bert_vectors\\batch_0738.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0419.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     47/Unknown \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9527 - loss: 0.1198Loading file: bert_vectors\\batch_0785.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0435.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     49/Unknown \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9517 - loss: 0.1223Loading file: bert_vectors\\batch_0019.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0653.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     51/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9509 - loss: 0.1245Loading file: bert_vectors\\batch_0894.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0153.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     53/Unknown \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9502 - loss: 0.1263Loading file: bert_vectors\\batch_0702.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0021.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     55/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9497 - loss: 0.1278Loading file: bert_vectors\\batch_0684.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0512.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     57/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9492 - loss: 0.1290Loading file: bert_vectors\\batch_0264.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0205.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     59/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9488 - loss: 0.1303Loading file: bert_vectors\\batch_0692.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0013.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     61/Unknown \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9484 - loss: 0.1313Loading file: bert_vectors\\batch_0488.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0463.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     63/Unknown \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9480 - loss: 0.1326Loading file: bert_vectors\\batch_0438.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0656.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     65/Unknown \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9476 - loss: 0.1341Loading file: bert_vectors\\batch_0804.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0726.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     67/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9472 - loss: 0.1356Loading file: bert_vectors\\batch_0052.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0270.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     69/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9469 - loss: 0.1370Loading file: bert_vectors\\batch_0389.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0922.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     71/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9466 - loss: 0.1381Loading file: bert_vectors\\batch_0602.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0669.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     73/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9464 - loss: 0.1391Loading file: bert_vectors\\batch_0932.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0909.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     75/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9462 - loss: 0.1400Loading file: bert_vectors\\batch_0475.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0610.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     77/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9460 - loss: 0.1408Loading file: bert_vectors\\batch_0113.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0626.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     79/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9458 - loss: 0.1415Loading file: bert_vectors\\batch_0634.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0106.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     81/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9456 - loss: 0.1424Loading file: bert_vectors\\batch_0865.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0822.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     83/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9454 - loss: 0.1432Loading file: bert_vectors\\batch_0376.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0852.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     85/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9452 - loss: 0.1439Loading file: bert_vectors\\batch_0718.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0379.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     87/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9450 - loss: 0.1447Loading file: bert_vectors\\batch_0150.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0058.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     89/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9446 - loss: 0.1457Loading file: bert_vectors\\batch_0643.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0192.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     91/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9443 - loss: 0.1467Loading file: bert_vectors\\batch_0570.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0103.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     93/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9440 - loss: 0.1475Loading file: bert_vectors\\batch_0816.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0524.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     95/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9437 - loss: 0.1483Loading file: bert_vectors\\batch_0676.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0193.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     97/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9434 - loss: 0.1490Loading file: bert_vectors\\batch_0624.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0884.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     99/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9432 - loss: 0.1497Loading file: bert_vectors\\batch_0135.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0617.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    101/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9429 - loss: 0.1504Loading file: bert_vectors\\batch_0667.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0594.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    103/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9427 - loss: 0.1510Loading file: bert_vectors\\batch_0497.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0242.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    105/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9424 - loss: 0.1517Loading file: bert_vectors\\batch_0042.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0278.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    107/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9420 - loss: 0.1524Loading file: bert_vectors\\batch_0639.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0181.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    109/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9417 - loss: 0.1530Loading file: bert_vectors\\batch_0693.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0244.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    111/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9415 - loss: 0.1536Loading file: bert_vectors\\batch_0216.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0243.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    113/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9413 - loss: 0.1540Loading file: bert_vectors\\batch_0528.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0988.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    115/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9411 - loss: 0.1545Loading file: bert_vectors\\batch_0976.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0208.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    117/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9409 - loss: 0.1548Loading file: bert_vectors\\batch_0733.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0830.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    119/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9407 - loss: 0.1552Loading file: bert_vectors\\batch_0303.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0779.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    121/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9406 - loss: 0.1555Loading file: bert_vectors\\batch_0747.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0464.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    123/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9404 - loss: 0.1558Loading file: bert_vectors\\batch_0406.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0180.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    125/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9402 - loss: 0.1562Loading file: bert_vectors\\batch_0946.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0082.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    127/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9401 - loss: 0.1565Loading file: bert_vectors\\batch_0110.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0690.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    129/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9399 - loss: 0.1568Loading file: bert_vectors\\batch_0861.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    130/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9399 - loss: 0.1569Loading file: bert_vectors\\batch_0724.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0333.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    132/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9398 - loss: 0.1572Loading file: bert_vectors\\batch_0071.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0902.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    134/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9397 - loss: 0.1575Loading file: bert_vectors\\batch_0450.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0241.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    136/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9396 - loss: 0.1577Loading file: bert_vectors\\batch_0754.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0401.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    138/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9395 - loss: 0.1579Loading file: bert_vectors\\batch_0654.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0077.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    140/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9394 - loss: 0.1581Loading file: bert_vectors\\batch_0815.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0011.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    142/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9394 - loss: 0.1583Loading file: bert_vectors\\batch_0036.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0882.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    144/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9393 - loss: 0.1585Loading file: bert_vectors\\batch_0443.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0812.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    146/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9392 - loss: 0.1588Loading file: bert_vectors\\batch_0782.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0843.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    148/Unknown \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.9390 - loss: 0.1592Loading file: bert_vectors\\batch_0750.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.9388 - loss: 0.1597\n",
      "Validation Loss: 0.18353955447673798\n",
      "Validation Accuracy: 0.9230132699012756\n"
     ]
    }
   ],
   "source": [
    "#  评估模型\n",
    "# 使用验证集（你已经分配的 val_dataset）来评估模型性能。这通常涉及计算模型在验证数据上的损失和准确率等指标。\n",
    "# 评估模型性能\n",
    "val_loss, val_accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: bert_vectors\\batch_0920.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0525.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      1/Unknown \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0052Loading file: bert_vectors\\batch_0567.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0657.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      3/Unknown \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9028 - loss: 0.2073Loading file: bert_vectors\\batch_0633.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0429.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      5/Unknown \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8967 - loss: 0.2230Loading file: bert_vectors\\batch_0857.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0712.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      7/Unknown \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9015 - loss: 0.2118Loading file: bert_vectors\\batch_0174.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0604.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "      9/Unknown \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9055 - loss: 0.2043Loading file: bert_vectors\\batch_0867.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0449.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     11/Unknown \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9076 - loss: 0.2031Loading file: bert_vectors\\batch_0846.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0580.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     13/Unknown \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9072 - loss: 0.2055Loading file: bert_vectors\\batch_0076.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0371.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     15/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9081 - loss: 0.2042Loading file: bert_vectors\\batch_0720.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0136.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     17/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9086 - loss: 0.2020Loading file: bert_vectors\\batch_0158.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0290.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     19/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9097 - loss: 0.1988Loading file: bert_vectors\\batch_0858.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0321.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     21/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9099 - loss: 0.1996Loading file: bert_vectors\\batch_0759.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0070.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     23/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9105 - loss: 0.1990Loading file: bert_vectors\\batch_0355.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0359.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     25/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9109 - loss: 0.1989Loading file: bert_vectors\\batch_0107.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0265.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     27/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9109 - loss: 0.2018Loading file: bert_vectors\\batch_0827.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0139.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     29/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9113 - loss: 0.2032Loading file: bert_vectors\\batch_0184.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0728.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     31/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9117 - loss: 0.2040Loading file: bert_vectors\\batch_0688.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0943.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     33/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9122 - loss: 0.2043Loading file: bert_vectors\\batch_0305.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0811.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     35/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9125 - loss: 0.2044Loading file: bert_vectors\\batch_0306.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0649.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     37/Unknown \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9129 - loss: 0.2045Loading file: bert_vectors\\batch_0972.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0323.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     39/Unknown \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9129 - loss: 0.2049Loading file: bert_vectors\\batch_0059.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0298.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     41/Unknown \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9131 - loss: 0.2048Loading file: bert_vectors\\batch_0628.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0618.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     43/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9133 - loss: 0.2045Loading file: bert_vectors\\batch_0370.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0023.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     45/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9134 - loss: 0.2049Loading file: bert_vectors\\batch_0030.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0757.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     47/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9135 - loss: 0.2054Loading file: bert_vectors\\batch_0010.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0514.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     49/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9138 - loss: 0.2055Loading file: bert_vectors\\batch_0737.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0598.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     51/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9142 - loss: 0.2052Loading file: bert_vectors\\batch_0810.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0551.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     53/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9146 - loss: 0.2048Loading file: bert_vectors\\batch_0620.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0334.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     55/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9147 - loss: 0.2050Loading file: bert_vectors\\batch_0237.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0591.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     57/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9148 - loss: 0.2051Loading file: bert_vectors\\batch_0198.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0430.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     59/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9149 - loss: 0.2055Loading file: bert_vectors\\batch_0363.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0532.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     61/Unknown \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9151 - loss: 0.2056Loading file: bert_vectors\\batch_0404.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0096.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     63/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9153 - loss: 0.2057Loading file: bert_vectors\\batch_0583.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0723.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     65/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9155 - loss: 0.2057Loading file: bert_vectors\\batch_0832.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0235.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     67/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9157 - loss: 0.2056Loading file: bert_vectors\\batch_0312.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0673.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     69/Unknown \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9159 - loss: 0.2054Loading file: bert_vectors\\batch_0937.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0039.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     71/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9162 - loss: 0.2050Loading file: bert_vectors\\batch_0213.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0482.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     73/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9165 - loss: 0.2045Loading file: bert_vectors\\batch_0933.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0066.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     75/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9168 - loss: 0.2041Loading file: bert_vectors\\batch_0924.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0067.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     77/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9171 - loss: 0.2036Loading file: bert_vectors\\batch_0883.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0485.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     79/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9173 - loss: 0.2031Loading file: bert_vectors\\batch_0168.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0318.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     81/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9175 - loss: 0.2028Loading file: bert_vectors\\batch_0687.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0362.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     83/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9177 - loss: 0.2024Loading file: bert_vectors\\batch_0581.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0215.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     85/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9180 - loss: 0.2020Loading file: bert_vectors\\batch_0806.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0294.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     87/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9183 - loss: 0.2015Loading file: bert_vectors\\batch_0088.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0063.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     89/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9186 - loss: 0.2009Loading file: bert_vectors\\batch_0905.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0710.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     91/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9189 - loss: 0.2004Loading file: bert_vectors\\batch_0597.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0895.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     93/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9192 - loss: 0.1999Loading file: bert_vectors\\batch_0210.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0652.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     95/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9196 - loss: 0.1994Loading file: bert_vectors\\batch_0817.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0954.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     97/Unknown \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9199 - loss: 0.1988Loading file: bert_vectors\\batch_0209.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0874.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "     99/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9202 - loss: 0.1984Loading file: bert_vectors\\batch_0947.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0980.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    101/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9205 - loss: 0.1979Loading file: bert_vectors\\batch_0307.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0086.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    103/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9208 - loss: 0.1974Loading file: bert_vectors\\batch_0665.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0519.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    105/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9210 - loss: 0.1969Loading file: bert_vectors\\batch_0930.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0625.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    107/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.1969Loading file: bert_vectors\\batch_0568.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0518.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    109/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9213 - loss: 0.1968Loading file: bert_vectors\\batch_0554.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0919.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    111/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9213 - loss: 0.1969Loading file: bert_vectors\\batch_0254.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0221.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    113/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9213 - loss: 0.1970Loading file: bert_vectors\\batch_0992.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0896.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    115/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9213 - loss: 0.1973Loading file: bert_vectors\\batch_0436.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0872.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    117/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9213 - loss: 0.1975Loading file: bert_vectors\\batch_0501.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0717.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    119/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9213 - loss: 0.1978Loading file: bert_vectors\\batch_0844.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0259.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    121/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.1981Loading file: bert_vectors\\batch_0990.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0526.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    123/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.1983Loading file: bert_vectors\\batch_0055.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0601.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    125/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.1986Loading file: bert_vectors\\batch_0531.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0120.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    127/Unknown \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.1989Loading file: bert_vectors\\batch_0783.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0025.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    129/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.1992Loading file: bert_vectors\\batch_0072.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0044.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    131/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.1995Loading file: bert_vectors\\batch_0231.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0352.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    133/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.1997Loading file: bert_vectors\\batch_0275.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0289.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    135/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.2000Loading file: bert_vectors\\batch_0675.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0668.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    137/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.2003Loading file: bert_vectors\\batch_0310.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0549.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    139/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.2006Loading file: bert_vectors\\batch_0697.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0478.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    141/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.2010Loading file: bert_vectors\\batch_0218.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0266.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    143/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.2013Loading file: bert_vectors\\batch_0936.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0286.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    145/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.2016Loading file: bert_vectors\\batch_0346.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0060.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "    147/Unknown \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9212 - loss: 0.2019Loading file: bert_vectors\\batch_0462.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "Loading file: bert_vectors\\batch_0993.npy\n",
      "Loaded data shape: (8, 512, 768) (8,)\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9211 - loss: 0.2026\n",
      "Test Loss: 0.23004844784736633\n",
      "Test Accuracy: 0.9114238619804382\n"
     ]
    }
   ],
   "source": [
    "# 模型测试\n",
    "# 使用测试集（test_dataset）来测试模型的泛化能力。这是评估模型在未见过的数据上表现的重要步骤。\n",
    "# 测试模型\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully in Keras format.\n"
     ]
    }
   ],
   "source": [
    "# 这儿，需要注意，是采用的keras格式保存模型，使用H5保存会出现bug\n",
    "model.save('trained_cnn_lstm_model_v1.keras')  # 使用 .keras 扩展名\n",
    "print(\"Model saved successfully in Keras format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 15 variables whereas the saved optimizer has 28 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('trained_cnn_lstm_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
